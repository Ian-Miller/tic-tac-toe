# モンテカルロ木探索三目並べ

[English](README.md) | [中文](README.zh-CN.md) | [日本語](#日本語) | [한국어](README.ko.md) | [Русский](README.ru.md) | [Français](README.fr.md) | [Español](README.es.md) | [Deutsch](README.de.md)

![ゲームプレビュー](preview.jpeg)
*注：preview.ja.jpegが存在する場合、代わりにそれが表示されます*

## オンラインゲーム

ここでオンラインでプレイできます：[https://ian-miller.github.io/tic-tac-toe/](https://ian-miller.github.io/tic-tac-toe/)

## プロジェクト紹介

これはモンテカルロ木探索（MCTS）アルゴリズムを使用して実装された三目並べゲームです。

このプロジェクトは、モンテカルロ木探索アルゴリズムを学ぶ過程での私の実践作品です。MCTSは意思決定プロセスに使用されるヒューリスティック探索アルゴリズムで、特にボードゲームにおけるAI実装に適しています。

## アルゴリズム紹介

### モンテカルロ木探索
モンテカルロ木探索は、ランダムシミュレーションを多数実行して手の評価を行う確率的なアルゴリズムです。

このゲームでは、AIがMCTSアルゴリズムを使用して以下のステップで最適な手を決定します：
1. 選択（Selection）：ルートノードから始め、UCB式を使用して最も有望な子ノードを選択します
2. 拡張（Expansion）：完全に拡張されていないノードに到達した場合、新しい子ノードを作成します
3. シミュレーション（Simulation）：新しいノードからゲーム終了までランダムにシミュレーションします
4. バックプロパゲーション（Backpropagation）：結果をすべての訪問済みノードに戻します

### ミニマックスアルゴリズム
ミニマックスアルゴリズムは、すべての可能なゲーム状態を再帰的に評価し、最適な手を見つける決定論的なアルゴリズムです。

このアルゴリズムには、温度パラメータの調整や緊急移動認識などの最適化戦略も含まれています。 